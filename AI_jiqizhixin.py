import os
import json
import asyncio
import time
from dotenv import load_dotenv
from openai import OpenAI
from seatable_api import Base
from playwright.async_api import async_playwright
from requests.exceptions import ReadTimeout
from bs4 import BeautifulSoup

# ========== ç¯å¢ƒåŠ è½½ ==========
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_API_BASE = os.getenv("OPENAI_API_BASE")
SEATABLE_API_TOKEN = os.getenv("SEATABLE_API_TOKEN")
SEATABLE_SERVER_URL = os.getenv("SEATABLE_SERVER_URL")

# ========== åˆå§‹åŒ– ==========
client = OpenAI(api_key=OPENAI_API_KEY, base_url=OPENAI_API_BASE)
base = Base(SEATABLE_API_TOKEN, SEATABLE_SERVER_URL)
base.auth()
table_name = "AIæ‘˜è¦"

# ========== å»é‡ç”¨ ==========
base_dir = r'C:\Users\kongg\0\spiders\ai_news'
output_file = os.path.join(base_dir, "jiqizhixin_articles_summarized.jsonl")
markdown_file = os.path.join(base_dir, "jiqizhixin_articles_summarized.md")
summarized_titles = set()
if os.path.exists(output_file):
    with open(output_file, "r", encoding="utf-8") as f:
        for line in f:
            try:
                data = json.loads(line)
                summarized_titles.add(data["title"])
            except:
                continue

# ========== æ‘˜è¦ç”Ÿæˆå‡½æ•° ==========
async def generate_summaries(title, content):
    try:
        print(f"âœï¸ æ­£åœ¨ç”Ÿæˆæ‘˜è¦: {title}")

        # ä¸­æ–‡æ‘˜è¦
        res_zh = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½èµ„æ·±ç§‘æŠ€ç¼–è¾‘ï¼Œæ“…é•¿æç‚¼å¤æ‚æ–‡ç« çš„æ ¸å¿ƒå†…å®¹ã€‚è¯·ç”¨ç®€æ´ã€ä¸“ä¸šã€å‡†ç¡®çš„è¯­è¨€ï¼Œç”Ÿæˆä¸€æ®µä¸è¶…è¿‡150å­—çš„ä¸­æ–‡æ‘˜è¦ï¼Œæ¦‚æ‹¬æ–‡ç« çš„ä¸»è¦è§‚ç‚¹ã€å…³é”®æ•°æ®ä¸ç»“è®ºï¼Œé¿å…ä¸»è§‚è¯„ä»·ï¼Œä¿æŒæ–°é—»æŠ¥é“é£æ ¼ã€‚"},
                {"role": "user", "content": f"ä»¥ä¸‹æ˜¯æ–‡ç« æ­£æ–‡ï¼Œè¯·ä¸ºå…¶æ’°å†™ä¸“ä¸šæ‘˜è¦ï¼š\n\n{content}"},
            ],
            temperature=0.5,
        )
        summary_zh = res_zh.choices[0].message.content.strip()

        # è‹±æ–‡æ‘˜è¦
        res_en = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "You are a professional tech journalist with expertise in summarizing complex articles. Please generate a concise and informative summary (no more than 100 words) that captures the article's key points, findings, and implications. Avoid subjective opinions and use a neutral, journalistic tone."},
                {"role": "user", "content": f"Here is the article content. Please write a high-quality English summary:\n\n{content}"},
            ],
            temperature=0.5,
        )
        summary_en = res_en.choices[0].message.content.strip()

        return summary_zh, summary_en

    except Exception as e:
        print(f"\nâŒ æ‘˜è¦ç”Ÿæˆå¤±è´¥: {title}\nåŸå› : {e}")
        return None, None


# ========== å¢åŠ è¶…æ—¶é‡è¯•çš„å‡½æ•° ==========
def safe_append_row_with_retry(base, table_name, row, retries=3, delay=5):
    for attempt in range(retries):
        try:
            insert_result = base.append_row(table_name, row)
            return insert_result
        except ReadTimeout as e:
            print(f"âš ï¸ å°è¯• {attempt + 1} å¤±è´¥ï¼Œè¶…æ—¶é”™è¯¯: {e}")
            if attempt < retries - 1:
                print(f"â³ ç­‰å¾… {delay} ç§’åé‡è¯•...")
                time.sleep(delay)
            else:
                print("âŒ é‡è¯•æ¬¡æ•°å·²è€—å°½ï¼Œè·³è¿‡æ’å…¥ã€‚")
                return None
        except Exception as e:
            print(f"âš ï¸ å‡ºç°å…¶ä»–é”™è¯¯: {e}")
            return None

# ========== ä¸»çˆ¬è™«é€»è¾‘ ==========
async def main():
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    os.makedirs(os.path.dirname(markdown_file), exist_ok=True)
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False)
        page = await browser.new_page()
        await page.goto("https://www.jiqizhixin.com/articles", timeout=60000)

        cards = await page.locator("div.article-card").all()

        with open(output_file, "a", encoding="utf-8") as f, \
             open(markdown_file, "a", encoding="utf-8") as md_f:
            for i, card in enumerate(cards):
                time_text = await card.locator("div.article-card__time").inner_text()
                print(f"â±ï¸ ç¬¬ {i + 1} ç¯‡æ–‡ç« æ—¶é—´: {time_text}")

                if "1å¤©å‰" in time_text:
                    print("ğŸ›‘ é‡åˆ°ã€1å¤©å‰ã€ï¼Œåœæ­¢æŠ“å–ã€‚")
                    break

                # è®¾ç½®ç›‘å¬
                try:
                    async with page.expect_response(
                        lambda res: "/api/v4/articles/" in res.url and res.status == 200,
                        timeout=60000  # åŠ é•¿ç­‰å¾…æ—¶é—´
                    ) as res_info:
                        print("ğŸ–±ï¸ ç‚¹å‡»æ–‡ç« ")
                        await card.click()

                    # ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½
                    await page.wait_for_load_state("load")

                    response = await res_info.value
                    data = await response.json()

                except Exception as e:
                    print(f"âš ï¸ é¡µé¢åŠ è½½å¤±è´¥ï¼Œè·³è¿‡è¯¥ç¯‡æ–‡ç« : {e}")
                    await page.goto("https://www.jiqizhixin.com/articles", timeout=60000)
                    cards = await page.locator("div.article-card").all()
                    continue

                title = data.get("title")
                published_at = data.get("published_at")
                html_content = data.get("content")

                if not title or not html_content:
                    continue
                if title in summarized_titles:
                    continue

                # æå–çº¯æ–‡æœ¬
                soup = BeautifulSoup(html_content, "html.parser")
                content = soup.get_text(separator="\n").strip()

                # è°ƒç”¨ AI ç”Ÿæˆæ‘˜è¦
                summary_cn, summary_en = await generate_summaries(title, content)
                if not summary_cn or not summary_en:
                    continue

                row = {
                    "title": title,
                    "published_at": published_at,
                    "content": content,
                    "summary_cn": summary_cn,
                    "summary_en": summary_en,
                }

                # å†™å…¥ JSONL
                f.write(json.dumps(row, ensure_ascii=False) + "\n")
                f.flush()
                summarized_titles.add(title)

                # å†™å…¥ Markdown
                md_f.write(f"## {title}\n")
                md_f.write(f"- å‘å¸ƒæ—¶é—´: {published_at}\n\n")
                md_f.write(f"**ä¸­æ–‡æ‘˜è¦ï¼š**\n\n{summary_cn}\n\n")
                md_f.write(f"**English Summary:**\n\n{summary_en}\n\n")
                md_f.write("---\n\n")
                md_f.flush()

                # æ’å…¥ SeaTableï¼Œå¢åŠ è¶…æ—¶é‡è¯•
                insert_result = safe_append_row_with_retry(base, table_name, row)
                if insert_result:
                    print(f"âœ… å·²æ’å…¥ SeaTable: {title}")

                # ç­‰å¾…ä¸€æ®µæ—¶é—´å†å¤„ç†ä¸‹ä¸€ç¯‡
                await page.wait_for_timeout(1000)

        await browser.close()

# è¿è¡Œçˆ¬è™«
asyncio.run(main())
